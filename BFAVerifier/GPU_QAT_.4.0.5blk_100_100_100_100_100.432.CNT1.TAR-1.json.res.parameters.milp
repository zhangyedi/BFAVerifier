2024-04-29 13:22:52.366306: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-29 13:22:52.366940: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-29 13:22:52.369070: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-29 13:22:52.379516: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-29 13:22:53.681358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2024-04-29 13:22:54.681604: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
/home/user/DPolyR/venv/lib/python3.10/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer TruncatedNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.
  warnings.warn(
key_list:  [(1, 0, 64), (1, 6, 37), (1, 6, 64), (1, 60, 64), (2, 65, 21), (2, 65, 45), (3, 45, 93), (3, 97, 64), (4, 27, 93), (5, 2, 20), (5, 2, 30), (5, 2, 4), (5, 2, 42), (5, 2, 5), (5, 2, 54), (5, 2, 65), (5, 2, 75), (5, 2, 76), (5, 2, 90), (5, 3, 54), (5, 4, 20), (5, 4, 22), (5, 4, 3), (5, 4, 4), (5, 4, 42), (5, 4, 5), (5, 4, 51), (5, 4, 54), (5, 4, 65), (5, 4, 66), (5, 4, 67), (5, 4, 76), (5, 6, 42), (5, 8, 42), (5, 8, 54), (5, 9, 51), (5, 9, 54)]
W:  {(1, 0, 64): [-3, -2, -8, 4], (1, 6, 37): [-5, -8, -2, 2], (1, 6, 64): [-2, -3, -5, 7], (1, 60, 64): [-4, -1, -7, 5], (2, 65, 21): [5, 6, 0, -4], (2, 65, 45): [5, 6, 0, -4], (3, 45, 93): [0, 3, 5, -7], (3, 97, 64): [-3, -2, -8, 4], (4, 27, 93): [-2, -3, -5, 7], (5, 2, 20): [-4, -1, -7, 5], (5, 2, 30): [-1, -4, -6, 6], (5, 2, 4): [-2, -3, -5, 7], (5, 2, 42): [3, 0, 6, -6], (5, 2, 5): [-1, -4, -6, 6], (5, 2, 54): [-1, -4, -6, 6], (5, 2, 65): [-2, -3, -5, 7], (5, 2, 75): [-1, -4, -6, 6], (5, 2, 76): [-3, -2, -8, 4], (5, 2, 90): [-2, -3, -5, 7], (5, 3, 54): [-2, -3, -5, 7], (5, 4, 20): [3, 0, 6, -6], (5, 4, 22): [1, 2, 4, -8], (5, 4, 3): [4, 7, 1, -3], (5, 4, 4): [2, 1, 7, -5], (5, 4, 42): [0, 3, 5, -7], (5, 4, 5): [2, 1, 7, -5], (5, 4, 51): [3, 0, 6, -6], (5, 4, 54): [0, 3, 5, -7], (5, 4, 65): [2, 1, 7, -5], (5, 4, 66): [1, 2, 4, -8], (5, 4, 67): [0, 3, 5, -7], (5, 4, 76): [2, 1, 7, -5], (5, 6, 42): [-1, -4, -6, 6], (5, 8, 42): [-2, -3, -5, 7], (5, 8, 54): [-1, -4, -6, 6], (5, 9, 51): [-6, -7, -1, 3], (5, 9, 54): [-2, -3, -5, 7]}
bfa_vecNum:  4
Set parameter Threads to value 30

1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 154ms/step

1/1 [==============================] - ETA: 0s
1/1 [==============================] - 0s 25ms/step

The output of ground-truth is:  [-2709.9304  -1760.0563    207.91753 -1689.4438   1188.2917   -839.05066
 -1435.545   -2562.2563  -1440.4076   -592.3577 ]
The robustness hold!

==================================== Now we start do ilp-based solving! ====================================
The num of vars:  1951
The num of numIntVars:  157
The num of numBinVars:  157
The num of Constraints:  2086
Set parameter TimeLimit to value 3600
Set parameter NonConvex to value 2
Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (linux64 - "Ubuntu 22.04.4 LTS")

CPU model: AMD EPYC 7742 64-Core Processor, instruction set [SSE2|AVX|AVX2]
Thread count: 128 physical cores, 128 logical processors, using up to 30 threads

Optimize a model with 2086 rows, 1951 columns and 105682 nonzeros
Model fingerprint: 0x961f2a06
Model has 13 quadratic constraints
Model has 500 general constraints
Variable types: 1794 continuous, 157 integer (157 binary)
Coefficient statistics:
  Matrix range     [2e-01, 1e+03]
  QMatrix range    [2e-01, 1e+00]
  QLMatrix range   [2e-01, 1e+00]
  Objective range  [0e+00, 0e+00]
  Bounds range     [1e+00, 1e+03]
  RHS range        [2e-02, 1e+03]
  QRHS range       [6e-01, 7e-01]
Presolve removed 735 rows and 678 columns
Presolve time: 0.59s

Explored 0 nodes (0 simplex iterations) in 0.60 seconds (0.27 work units)
Thread count was 1 (of 128 available processors)

Solution count 0

Model is infeasible
Best objective -, best bound -, gap -

The total encoding time is: 2.2083029747009277

The total solving time is: 0.6119112968444824

The total time is: 2.82021427154541
BFA-tolerant Robustness Property is True.
{'encoding_time': 2.2083029747009277, 'solving_time': 0.6119112968444824, 'total_time': 2.82021427154541, 'solving_res': False}

The BFA-tolerant robustness property holds w.r.t. all (1,1)-attack vectors for the input sample 0432!
